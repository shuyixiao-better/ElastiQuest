{
  "version": "1.0",
  "records": [
    {
      "filePath": "E:/Project/hzmj/ais-server/src/main/java/com/torchv/application/system/web/RagConfigLlmModelController.java",
      "timestamp": 1762223814435,
      "startOffset": 979,
      "endOffset": 1060,
      "codeContent": "q.RagConfigLlmModelListedToggleReq;\nimport com.torchv.application.system.model.re",
      "aiProbability": 90,
      "aiTool": "AI Assistant",
      "detectionMethod": "REALTIME_SPEED_ANALYSIS",
      "lineCount": 2
    },
    {
      "filePath": "E:/Project/hzmj/ais-server/src/main/java/com/torchv/application/system/service/impl/RagConfigLlmModelServiceImpl.java",
      "timestamp": 1762223814494,
      "startOffset": 39364,
      "endOffset": 40969,
      "codeContent": "    /**\n     * 根据模型编码切换上下架状态\n     * @param toggleReq 上下架切换请求\n     * @return 是否成功\n     */\n    @Override\n    public Result\u003cString\u003e toggleListed(RagConfigLlmModelListedToggleReq toggleReq) {\n        log.info(\"根据模型编码切换上下架状态, modelCode: {}, listed: {}\", \n            toggleReq.getModelCode(), toggleReq.getListed());\n        \n        // 根据模型编码查询\n        String tenantId \u003d UserContextHolder.getTenantId();\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e modelWrapper \u003d Wrappers.lambdaQuery(RagConfigLlmModel.class);\n        modelWrapper.eq(RagConfigLlmModel::getModelCode, toggleReq.getModelCode());\n        modelWrapper.eq(RagConfigLlmModel::getTenantId, tenantId);\n        RagConfigLlmModel record \u003d ragConfigLlmModelMapper.selectOne(modelWrapper);\n        \n        Assert.notNull(record, \"system.common.request.invalid\");\n        \n        // 更新上下架状态\n        RagConfigLlmModel ragConfigLlmModel \u003d new RagConfigLlmModel();\n        ragConfigLlmModel.setId(record.getId());\n        ragConfigLlmModel.setListed(toggleReq.getListed());\n        ragConfigLlmModel.setModifierTime(LocalDateTime.now());\n        ragConfigLlmModel.setModifier(UserContextHolder.getCurrentUser().getCode());\n        \n        int ret \u003d ragConfigLlmModelMapper.updateById(ragConfigLlmModel);\n        if (ret \u003e 0) {\n            // 删除缓存\n            this.clear(List.of(record.getModel(), record.getName()));\n        }\n        \n        return ret \u003e 0 \n            ? Result.defaultSuccess(i18nMessage.resolveMessage(\"system.common.update.success\")) \n            : Result.error(i18nMessage.resolveMessage(\"system.common.update.fail\"));\n    }\n    \n",
      "aiProbability": 95,
      "aiTool": "AI Assistant",
      "detectionMethod": "REALTIME_SPEED_ANALYSIS",
      "lineCount": 38
    },
    {
      "filePath": "E:/Project/hzmj/ais-server/src/main/java/com/torchv/application/system/web/RagConfigLlmModelController.java",
      "timestamp": 1762223831501,
      "startOffset": 7472,
      "endOffset": 7972,
      "codeContent": "    /**\n     * 根据模型编码切换上下架状态\n     * @param toggleReq 上下架切换请求\n     * @return 是否成功\n     */\n    @Operation(summary \u003d \"根据模型编码切换上下架状态\")\n    @PutMapping(\"/toggleListed\")\n    public Result\u003cString\u003e toggleListed(@Valid @RequestBody RagConfigLlmModelListedToggleReq toggleReq) {\n        log.info(\"根据模型编码切换上下架状态,API:{},modelCode:{},listed:{}\", \n            \"/rag/config/llm/toggleListed\", toggleReq.getModelCode(), toggleReq.getListed());\n        return ragConfigLlmModelService.toggleListed(toggleReq);\n    }\n\n",
      "aiProbability": 70,
      "aiTool": "AI Assistant",
      "detectionMethod": "REALTIME_SPEED_ANALYSIS",
      "lineCount": 14
    },
    {
      "filePath": "E:/Project/hzmj/ais-server/src/main/java/com/torchv/infra/rag/constant/ModelProviders.java",
      "timestamp": 1762225670625,
      "startOffset": 1753,
      "endOffset": 4757,
      "codeContent": ", \"zijie-model-studio-models.yaml\", \"ZIJIE\"),\n    Q_WEN(100, \"通义千问\", \"qwen\", \"\", \"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation\", QWenOpenSourceSupplier.class, \"aliyun-model-studio-models.yaml\", \"ALIYUN\"),\n    DeepSeek(200, \"DeepSeek\", \"deepseek\", \"\", \"https://api.deepseek.com/v1/chat/completions\", DeepSeekTurboSupplier.class, \"deepseek-model-studio-models.yaml\", \"DEEPSEEK\"),\n    MoonShot(300, \"月之暗面\", \"moon-shot\", \"MoonShot\", \"https://api.moonshot.cn/v1/chat/completions\", MoonShotSupplier.class, null, null),\n    ChatGLM(400, \"智谱AI\", \"chat-glm\", \"智谱推出的大模型\", \"https://open.bigmodel.cn/api/paas/v4/chat/completions\", ChatGLMTurboSupplier.class, \"zhipu-model-studio-models.yaml\", \"ZHIPU\"),\n    ZeroYi(500, \"零一万物\", \"zero-yi\", \"\", \"https://api.lingyiwanwu.com/v1/chat/completions\", ZeroYiSupplier.class, null, null),\n    Baichuan(600, \"百川智能\", \"baichuan\", \"\", \"https://api.baichuan-ai.com/v1/chat/completions\", BcTurboSupplier.class, \"baichuan-model-studio-models.yaml\", \"BAICHUAN\"),\n    MiniMax(700, \"MiniMax\", \"minimax\", \"上海稀宇科技有限公司\", \"https://api.minimax.chat/v1/text/chatcompletion_v2\", MiniMaxTurboSupplier.class, null, null),\n    OSC(800, \"开源中国\", \"osc\", \"OSChina\", \"https://ai.gitee.com/api/serverless/Qwen2-7B-Instruct/chat/completions\", LocalTurboSupplier.class, null, null),\n    Baidu(900, \"文心一言\", \"baidu\", \"百度\", \"\", LocalTurboSupplier.class, \"baidu-model-studio-models.yaml\", \"BAIDU\"),\n    Tencent(1000, \"腾讯\", \"tencent\", \"腾讯\", \"\", LocalTurboSupplier.class, \"hunyuan-model-studio-models.yaml\", \"HUNYUAN\"),\n    \n    OpenAI(1100, \"OpenAI\", \"chat-openai\", \"OpenAI模型\", \"https://api.openai.com/v1/chat/completions\", OpenAISupplier.class, null, null),\n    Anthropic(1200, \"Anthropic\", \"anthropic\", \"Anthropic\", \"\", LocalTurboSupplier.class, null, null),\n    Google(1300, \"Google\", \"google\", \"谷歌\", \"\", LocalTurboSupplier.class, null, null),\n    Cohere(1400, \"Cohere\", \"cohere\", \"Cohere\", \"\", LocalTurboSupplier.class, null, null),\n    Azure(1500, \"Azure\", \"azure\", \"Azure\", \"\", LocalTurboSupplier.class, null, null),\n    Ollama(1600, \"Ollama\", \"ollama\", \"Ollama\", \"\", LocalTurboSupplier.class, null, null),\n    Nvidia(1700, \"Nvidia\", \"nvidia\", \"Nvidia\", \"\", LocalTurboSupplier.class, null, null),\n    HuggingFace(1800, \"HuggingFace\", \"huggingface\", \"HuggingFace\", \"\", LocalTurboSupplier.class, null, null),\n    Amazon(1900, \"Amazon\", \"amazon\", \"Amazon\", \"\", LocalTurboSupplier.class, null, null),\n    \n    None(2000, \"None\", \"None\", \"系统\", \"\", LocalTurboSupplier.class, null, null);\n    \n    final int sort;\n    /**\n     * 品牌名称\n     */\n    final String name;\n    /**\n     * 图标\n     */\n    final String icon;\n    /**\n     * 简介\n     */\n    final String description;\n    \n    /**\n     * 接口地址\n     */\n    final String apiUrl;\n    /**\n     * 大模型的类型\n     */\n    final Class\u003c? extends LLMSupplier\u003e llmSupplierClazz;\n    \n    /**\n     * 配置文件名称（用于批量保存模型配置）\n     */\n    final String configFileName;\n    \n    /**\n     * 厂商编码（用于查找 plugin_vendor 表）\n     */\n    final String vendorCode",
      "aiProbability": 95,
      "aiTool": "AI Assistant",
      "detectionMethod": "REALTIME_SPEED_ANALYSIS",
      "lineCount": 56
    },
    {
      "filePath": "E:/Project/hzmj/ais-server/src/main/java/com/torchv/infra/rag/constant/ModelProviders.java",
      "timestamp": 1762225700664,
      "startOffset": 5103,
      "endOffset": 6625,
      "codeContent": "    \n    /**\n     * 根据品牌名称获取实例（中文名称）\n     * @param brandName 品牌名称（中文）\n     * @return 实例\n     */\n    public static ModelProviders getByName(String brandName) {\n        for (ModelProviders value : values()) {\n            if (StrUtil.equalsIgnoreCase(brandName, value.getName())) {\n                return value;\n            }\n        }\n        return None;\n    }\n    \n    /**\n     * 根据配置文件名获取实例\n     * @param configFileName 配置文件名\n     * @return 实例，如果未找到返回 null\n     */\n    public static ModelProviders getByConfigFileName(String configFileName) {\n        if (StrUtil.isBlank(configFileName)) {\n            return null;\n        }\n        for (ModelProviders value : values()) {\n            if (StrUtil.isNotBlank(value.getConfigFileName()) \u0026\u0026 value.getConfigFileName().equals(configFileName)) {\n                return value;\n            }\n        }\n        return null;\n    }\n    \n    /**\n     * 根据厂商编码获取实例\n     * @param vendorCode 厂商编码\n     * @return 实例，如果未找到返回 null\n     */\n    public static ModelProviders getByVendorCode(String vendorCode) {\n        if (StrUtil.isBlank(vendorCode)) {\n            return null;\n        }\n        for (ModelProviders value : values()) {\n            if (StrUtil.isNotBlank(value.getVendorCode()) \u0026\u0026 value.getVendorCode().equalsIgnoreCase(vendorCode)) {\n                return value;\n            }\n        }\n        return null;\n    }\n    \n    /**\n     * 是否有配置文件\n     * @return 是否有配置文件\n     */\n    public boolean hasConfigFile() {\n        return StrUtil.isNotBlank(this.configFileName);\n    }\n",
      "aiProbability": 70,
      "aiTool": "AI Assistant",
      "detectionMethod": "REALTIME_SPEED_ANALYSIS",
      "lineCount": 57
    },
    {
      "filePath": "E:/Project/hzmj/ais-server/src/main/java/com/torchv/application/system/service/impl/RagConfigLlmModelServiceImpl.java",
      "timestamp": 1762225700665,
      "startOffset": 3406,
      "endOffset": 31161,
      "codeContent": "model.req.RagConfigLlmModelBatchSaveReq;\nimport com.torchv.application.system.model.req.RagConfigLlmModelListedToggleReq;\nimport com.torchv.application.system.model.dto.ModelConfigDTO;\nimport com.torchv.infra.rag.constant.ModelProviders;\nimport com.torchv.repository.system.entity.PluginVendor;\nimport com.torchv.repository.system.mapper.PluginVendorMapper;\nimport org.springframework.core.io.ClassPathResource;\nimport org.yaml.snakeyaml.Yaml;\nimport com.google.gson.Gson;\nimport com.google.gson.GsonBuilder;\n\nimport java.io.InputStream;\nimport java.math.BigDecimal;\nimport java.util.*;\nimport java.time.LocalDateTime;\nimport java.util.function.Function;\n\n/**\n * 大模型配置模块-业务Service实现\n * @since torchv_server v0.1-beta.1\n * @author \u003ca href\u003d\"mailto:xiaoymin@foxmail.com\"\u003exiaoymin@foxmail.com\u003c/a\u003e\n * 2023/12/29 14:31\n */\n@Slf4j\n@AllArgsConstructor\n@Service\npublic class RagConfigLlmModelServiceImpl implements RagConfigLlmModelService {\n\n    final RagConfigLlmModelMapper ragConfigLlmModelMapper;\n    final StringRedisTemplate stringRedisTemplate;\n    final I18nMessage i18nMessage;\n    final ObjectMapper objectMapper \u003d new ObjectMapper();\n    final PluginVendorMapper pluginVendorMapper;\n    final Gson gson \u003d new GsonBuilder().setLenient().create();\n\n    @Override\n    public Result\u003cList\u003cRagConfigModelBrandResp\u003e\u003e providers() {\n        return Result.data(Arrays.stream(ModelProviders.values()).filter(providers -\u003e providers !\u003d ModelProviders.None).map(RagConfigModelBrandResp::of).toList());\n    }\n\n    @Override\n    public List\u003cUniversalEmbeddingConfig\u003e findEmbeddingModelsByTenantId(String tenantId) {\n        // 从数据库中查询\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d Wrappers.lambdaQuery(RagConfigLlmModel.class);\n        // 查询可用的模型\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getOnlineStatus, ToggleStatusEnum.YES.getValue()).eq(RagConfigLlmModel::getTenantId,tenantId);\n        //找嵌入模型\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getModelPurpose, LargeModelType.EMBEDDING_MODELS.name());\n        // 由于不限制模型编码，因此可以有多个服务厂商来提供负载支持，随机获取一个\n        List\u003cRagConfigLlmModel\u003e ragConfigLlmModels \u003d ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n        if (CollUtil.isNotEmpty(ragConfigLlmModels)) {\n            return ragConfigLlmModels.stream()\n                    .map(model -\u003e UniversalEmbeddingConfig.fromJson(model.getOtherConfig()))\n                    .toList();\n        }\n        return List.of();\n    }\n\n    @Override\n    public List\u003cUniversalReRankerConfig\u003e findReRankerModelsByTenantId(String tenantId) {\n        // 从数据库中查询\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d Wrappers.lambdaQuery(RagConfigLlmModel.class);\n        // 查询可用的模型\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getOnlineStatus, ToggleStatusEnum.YES.getValue()).eq(RagConfigLlmModel::getTenantId,tenantId);\n        //找嵌入模型\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getModelPurpose, LargeModelType.RERANK_MODELS.name());\n        // 由于不限制模型编码，因此可以有多个服务厂商来提供负载支持，随机获取一个\n        List\u003cRagConfigLlmModel\u003e ragConfigLlmModels \u003d ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n        if (CollUtil.isNotEmpty(ragConfigLlmModels)) {\n            return ragConfigLlmModels.stream()\n                    .map(model -\u003e UniversalReRankerConfig.fromJson(model.getOtherConfig()))\n                    .toList();\n        }\n        return List.of();\n    }\n\n    @Override\n    public void clear(List\u003cString\u003e models) {\n        Set\u003cString\u003e keys \u003d new HashSet\u003c\u003e();\n        for (String model : models) {\n            keys.add(ModelSetting.cacheKey(model));\n        }\n        keys.add(CacheCns.CACHE_MODEL_AVAILABLE_SETTING);\n        stringRedisTemplate.delete(keys);\n    }\n\n    @Override\n    public void checkExists(String modelName,String tenantId) {\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d Wrappers.lambdaQuery(RagConfigLlmModel.class);\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getModel, modelName);\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getTenantId, tenantId);\n        Assert.isFalse(ragConfigLlmModelMapper.exists(lambdaQueryWrapper), \"模型编码[\" + modelName + \"]已经存在。\");\n    }\n\n    @Override\n    public Optional\u003cRagConfigLlmModel\u003e findByModelName(String modelName) {\n        // 从数据库中查询\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d Wrappers.lambdaQuery(RagConfigLlmModel.class);\n        // 查询可用的模型\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getOnlineStatus, ToggleStatusEnum.YES.getValue());\n        // 模型编码或者名称都支持\n        lambdaQueryWrapper.and(l -\u003e l.eq(RagConfigLlmModel::getModel, modelName).or().eq(RagConfigLlmModel::getName, modelName));\n        // 由于不限制模型编码，因此可以有多个服务厂商来提供负载支持，随机获取一个\n        List\u003cRagConfigLlmModel\u003e ragConfigLlmModels \u003d ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n        if (CollUtil.isNotEmpty(ragConfigLlmModels)){\n            return Optional.of(ragConfigLlmModels.get(0));\n        }\n        return Optional.empty();\n    }\n\n    @Override\n    public Map\u003cString, UniversalEmbeddingConfig\u003e findEmbeddingByModelNames(List\u003cString\u003e modelNames) {\n        // 从数据库中查询\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d Wrappers.lambdaQuery(RagConfigLlmModel.class);\n        // 查询可用的模型\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getOnlineStatus, ToggleStatusEnum.YES.getValue());\n        // 模型编码或者名称都支持\n        lambdaQueryWrapper.and(l -\u003e l.in(RagConfigLlmModel::getModel, modelNames).or().in(RagConfigLlmModel::getName, modelNames));\n        // 由于不限制模型编码，因此可以有多个服务厂商来提供负载支持，随机获取一个\n        List\u003cRagConfigLlmModel\u003e ragConfigLlmModels \u003d ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n        if (CollUtil.isEmpty(ragConfigLlmModels)){\n            return Map.of();\n        }\n        Map\u003cString, UniversalEmbeddingConfig\u003e result \u003d new HashMap\u003c\u003e();\n        for (RagConfigLlmModel ragConfigLlmModel : ragConfigLlmModels) {\n            UniversalEmbeddingConfig embeddingConfig \u003d UniversalEmbeddingConfig.fromJson(ragConfigLlmModel.getOtherConfig());\n            if (embeddingConfig\u003d\u003dnull){\n                continue;\n            }\n            result.put(ragConfigLlmModel.getModel(), embeddingConfig);\n            result.put(ragConfigLlmModel.getName(), embeddingConfig);\n        }\n        return result;\n    }\n\n    /**\n     * 分页查询-大模型配置列表数据\n     * @param ragConfigLlmModelQueryReq 查询条件Vo\n     * @param pageNo 当前页码\n     * @param pageSize 每页页码大小\n     * @return 大模型配置列表\n     */\n    @Override\n    public Pagination\u003cRagConfigLlmModelResp\u003e list(RagConfigLlmModelQueryReq ragConfigLlmModelQueryReq, Integer pageNo, Integer pageSize) {\n        log.info(\"分页查询大模型配置列表,pageNo:{},pageSize:{}\", pageNo, pageSize);\n        log.info(\"分页QueryReq:{}\", ragConfigLlmModelQueryReq.toString());\n        // 获取租户编码\n        String tenantId \u003d UserContextHolder.getTenantId();\n        Page\u003cRagConfigLlmModel\u003e ragConfigLlmModelPageNo \u003d PageHelper.startPage(pageNo, pageSize);\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d Wrappers.lambdaQuery(RagConfigLlmModel.class);\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getTenantId, tenantId);\n        lambdaQueryWrapper.eq(StrUtil.isNotBlank(ragConfigLlmModelQueryReq.getBrand()), RagConfigLlmModel::getBrand, ragConfigLlmModelQueryReq.getBrand());\n        lambdaQueryWrapper.eq(StrUtil.isNotBlank(ragConfigLlmModelQueryReq.getModelPurpose()), RagConfigLlmModel::getModelPurpose, ragConfigLlmModelQueryReq.getModelPurpose());\n        lambdaQueryWrapper.like(StrUtil.isNotBlank(ragConfigLlmModelQueryReq.getModel()), RagConfigLlmModel::getModel, ragConfigLlmModelQueryReq.getModel());\n        lambdaQueryWrapper.like(StrUtil.isNotBlank(ragConfigLlmModelQueryReq.getName()), RagConfigLlmModel::getName, ragConfigLlmModelQueryReq.getName());\n        lambdaQueryWrapper.eq(ragConfigLlmModelQueryReq.getVendorCode() !\u003d null, RagConfigLlmModel::getVendorCode, ragConfigLlmModelQueryReq.getVendorCode());\n        lambdaQueryWrapper.eq(StrUtil.isNotBlank(ragConfigLlmModelQueryReq.getProvider()), RagConfigLlmModel::getProvider, ragConfigLlmModelQueryReq.getProvider());\n        lambdaQueryWrapper.eq(ragConfigLlmModelQueryReq.getListed() !\u003d null, RagConfigLlmModel::getListed, ragConfigLlmModelQueryReq.getListed());\n        List\u003cRagConfigLlmModel\u003e ragConfigLlmModelInfos \u003d ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n        List\u003cRagConfigLlmModelResp\u003e ragConfigLlmModelRespInfos \u003d new ArrayList\u003c\u003e();\n        long count \u003d ragConfigLlmModelPageNo.getTotal();\n        if (CollectionUtil.isNotEmpty(ragConfigLlmModelInfos)) {\n            ragConfigLlmModelRespInfos.addAll(ragConfigLlmModelInfos.stream().map(new RagConfigLlmModelApplyFunction(false)).toList());\n        }\n        return Pagination.pagination(ragConfigLlmModelRespInfos, count, pageNo, pageSize);\n    }\n    /**\n     * 新增大模型配置记录\n     * @param ragConfigLlmModelAddReq 新增大模型配置条件Vo\n     * @return 是否新增成功\n     */\n    @Transactional(rollbackFor \u003d Exception.class)\n    @Override\n    public Result\u003cString\u003e add(RagConfigLlmModelAddReq ragConfigLlmModelAddReq) {\n        log.info(\"新增大模型配置数据,Vo:{}\", ragConfigLlmModelAddReq.toString());\n        // 获取用户信息\n        SysUserInfo currentUser \u003d UserContextHolder.getCurrentUser();\n        // 获取租户编码\n        String tenantId \u003d currentUser.getTenantId();\n        // 根据模型编码查询，如果存在则不允许新增 增加租户级别筛选\n        this.checkExists(ragConfigLlmModelAddReq.getModel(),tenantId);\n        RagConfigLlmModel ragConfigLlmModel \u003d new RagConfigLlmModel();\n        BeanUtils.copyProperties(ragConfigLlmModelAddReq, ragConfigLlmModel);\n        if (StrUtil.isBlank(ragConfigLlmModelAddReq.getThinkingStatus())) {\n            // 如果思考状态没有设置，则默认设置为否\n            ragConfigLlmModel.setThinkingStatus(ToggleStatusEnum.NO.getValue());\n        }\n        // 生成唯一模型关联编码\n        String modelCode \u003d IdUtil.getSnowflakeNextIdStr();\n        ragConfigLlmModel.setCreateTime(LocalDateTime.now());\n        ragConfigLlmModel.setModifierTime(LocalDateTime.now());\n        ragConfigLlmModel.setModelCode(modelCode);\n        ragConfigLlmModel.setTenantId(tenantId);\n        ragConfigLlmModel.setCreator(currentUser.getCode());\n        ragConfigLlmModel.setModifier(currentUser.getCode());\n        ModelProviders modelProviders \u003d ModelProviders.of(ragConfigLlmModel.getBrand());\n        if (modelProviders \u003d\u003d ModelProviders.None) {\n            throw new IllegalArgumentException(\"模型厂商不支持\");\n        }\n        // 判断类型\n        if (LargeModelType.EMBEDDING_MODELS.name().equals(ragConfigLlmModel.getModelPurpose())){\n            // 处理为embedding的模型配置\n            ragConfigLlmModel.setOtherConfig(ragConfigLlmModelAddReq.embeddingConfig().toJson());\n        }else if (LargeModelType.RERANK_MODELS.name().equalsIgnoreCase(ragConfigLlmModel.getModelPurpose())) {\n            // 处理为rerank的模型配置\n            ragConfigLlmModel.setOtherConfig(ragConfigLlmModelAddReq.rankConfig().toJson());\n        }else if (LargeModelType.OCR_MODELS.name().equalsIgnoreCase(ragConfigLlmModel.getModelPurpose())) {\n            // 处理为大语言模型的配置\n            ragConfigLlmModel.setOtherConfig(ragConfigLlmModelAddReq.ocrConfig().toJson());\n        }\n        int ret \u003d ragConfigLlmModelMapper.insert(ragConfigLlmModel);\n        return ret \u003e 0 ? Result.defaultSuccess(i18nMessage.resolveMessage(\"system.common.add.success\")) : Result.error(i18nMessage.resolveMessage(\"system.common.add.fail\"));\n    }\n\n    /**\n     * 更新大模型配置记录\n     * @param ragConfigLlmModelUpdateReq 更新大模型配置条件Vo\n     * @return 是否更新成功\n     */\n    @Override\n    public Result\u003cString\u003e update(RagConfigLlmModelUpdateReq ragConfigLlmModelUpdateReq) {\n        log.info(\"根据主键id修改大模型配置数据,Vo:{}\", ragConfigLlmModelUpdateReq.toString());\n        RagConfigLlmModel record \u003d ragConfigLlmModelMapper.selectById(ragConfigLlmModelUpdateReq.getId());\n        Assert.notNull(record, \"system.common.request.invalid\");\n        if (!StrUtil.equalsIgnoreCase(record.getModel(), ragConfigLlmModelUpdateReq.getModel())) {\n            // 模型编码发生了变更，去重\n            this.checkExists(ragConfigLlmModelUpdateReq.getModel(),UserContextHolder.getTenantId());\n        }\n        ModelProviders modelProviders \u003d ModelProviders.of(record.getBrand());\n        if (modelProviders \u003d\u003d ModelProviders.None) {\n            throw new IllegalArgumentException(\"模型厂商不支持\");\n        }\n        RagConfigLlmModel ragConfigLlmModel \u003d new RagConfigLlmModel();\n        BeanUtils.copyProperties(ragConfigLlmModelUpdateReq, ragConfigLlmModel);\n        if (StrUtil.isBlank(ragConfigLlmModelUpdateReq.getThinkingStatus())) {\n            // 如果思考状态没有设置，则默认设置为否\n            ragConfigLlmModel.setThinkingStatus(ToggleStatusEnum.NO.getValue());\n        }\n        ragConfigLlmModel.setModifierTime(LocalDateTime.now());\n        // 判断类型\n        if (LargeModelType.EMBEDDING_MODELS.name().equals(ragConfigLlmModel.getModelPurpose())){\n            // 处理为embedding的模型配置\n            ragConfigLlmModel.setOtherConfig(ragConfigLlmModelUpdateReq.embeddingConfig().toJson());\n        }\n        else if (LargeModelType.RERANK_MODELS.name().equalsIgnoreCase(ragConfigLlmModel.getModelPurpose())) {\n            // 处理为rerank的模型配置\n            ragConfigLlmModel.setOtherConfig(ragConfigLlmModelUpdateReq.rankConfig().toJson());\n        }else if (LargeModelType.OCR_MODELS.name().equalsIgnoreCase(ragConfigLlmModel.getModelPurpose())) {\n            // 处理为大语言模型的配置\n            ragConfigLlmModel.setOtherConfig(ragConfigLlmModelUpdateReq.ocrConfig().toJson());\n        }\n        int ret \u003d ragConfigLlmModelMapper.updateById(ragConfigLlmModel);\n        if (ret \u003e 0) {\n            // 删除缓存\n            this.clear(List.of(record.getModel(), record.getName(), ragConfigLlmModelUpdateReq.getModel(), ragConfigLlmModelUpdateReq.getName()));\n        }\n        return ret \u003e 0 ? Result.defaultSuccess(i18nMessage.resolveMessage(\"system.common.update.success\")) : Result.error(i18nMessage.resolveMessage(\"system.common.update.fail\"));\n    }\n\n    @Override\n    public Result\u003cString\u003e toggle(RagConfigLlmModelUseToggleReq toggleReq) {\n        RagConfigLlmModel record \u003d ragConfigLlmModelMapper.selectById(toggleReq.getId());\n        Assert.notNull(record, \"system.common.request.invalid\");\n        RagConfigLlmModel ragConfigLlmModel \u003d new RagConfigLlmModel();\n        ragConfigLlmModel.setModifierTime(LocalDateTime.now());\n        if (StrUtil.equalsIgnoreCase(ToggleStatusEnum.YES.getValue(), record.getOnlineStatus())) {\n            ragConfigLlmModel.setOnlineStatus(ToggleStatusEnum.NO.getValue());\n        } else {\n            ragConfigLlmModel.setOnlineStatus(ToggleStatusEnum.YES.getValue());\n        }\n        ragConfigLlmModel.setId(toggleReq.getId());\n        int ret \u003d ragConfigLlmModelMapper.updateById(ragConfigLlmModel);\n        if (ret \u003e 0) {\n            // 删除缓存\n            this.clear(List.of(record.getModel(), record.getName()));\n        }\n        return ret \u003e 0 ? Result.defaultSuccess(i18nMessage.resolveMessage(\"system.common.update.success\")) : Result.error(i18nMessage.resolveMessage(\"system.common.update.fail\"));\n    }\n\n    /**\n     * 根据id查询大模型配置详情\n     * @param id 大模型配置主键id\n     * @return 大模型配置详情\n     */\n    @Override\n    public Result\u003cRagConfigLlmModelResp\u003e queryById(Integer id) {\n        log.info(\"根据主键id查询大模型配置详情,Id:{}\", id);\n        RagConfigLlmModel ragConfigLlmModel \u003d ragConfigLlmModelMapper.selectById(id);\n        Assert.notNull(ragConfigLlmModel, \"system.common.request.invalid\");\n        RagConfigLlmModelResp ragConfigLlmModelResp \u003d new RagConfigLlmModelApplyFunction(true).apply(ragConfigLlmModel);\n        return Result.data(ragConfigLlmModelResp);\n    }\n\n    /**\n     * 根据主键id批量删除大模型配置\n     * @param ids 批量删除主键id集合\n     * @return 是否删除成功\n     */\n    @Override\n    public Result\u003cString\u003e delete(List\u003cInteger\u003e ids) {\n        log.info(\"批量删除大模型配置,pageSize:{}\", CollectionUtil.size(ids));\n        int ret \u003d ragConfigLlmModelMapper.deleteBatchIds(ids);\n        return ret \u003e 0 ? Result.defaultSuccess(i18nMessage.resolveMessage(\"system.common.delete.success\")) : Result.error(i18nMessage.resolveMessage(\"system.common.delete.fail\"));\n    }\n\n    /**\n     * 根据主键id删除大模型配置\n     * @param id 主键id\n     * @return 是否删除成功\n     */\n    @Transactional(rollbackFor \u003d Exception.class)\n    @Override\n    public Result\u003cString\u003e delete(Integer id) {\n        log.info(\"根据主键id删除大模型配置,id:{}\", id);\n        RagConfigLlmModel record \u003d ragConfigLlmModelMapper.selectById(id);\n        Assert.notNull(record, \"system.common.request.invalid\");\n        int ret \u003d ragConfigLlmModelMapper.deleteById(id);\n        if (ret \u003e 0) {\n            // 删除缓存\n            this.clear(List.of(record.getModel(), record.getName()));\n        }\n        return ret \u003e 0 ? Result.defaultSuccess(i18nMessage.resolveMessage(\"system.common.delete.success\")) : Result.error(i18nMessage.resolveMessage(\"system.common.delete.fail\"));\n    }\n\n    /**\n     * 根据id查询大模型配置实体详情\n     * @param id 主键id\n     * @return 大模型配置的Optional\n     */\n    @Override\n    public Optional\u003cRagConfigLlmModel\u003e queryInfoById(Integer id) {\n        log.info(\"根据请求id查询大模型配置实体详情,id:{}\", id);\n        RagConfigLlmModel ragConfigLlmModel \u003d ragConfigLlmModelMapper.selectById(id);\n        if (ragConfigLlmModel !\u003d null) {\n            return Optional.of(ragConfigLlmModel);\n        }\n        return Optional.empty();\n    }\n\n    /**\n     * 组装查询条件\n     * @param tenantId 租户id\n     * @return LambdaQueryWrapper\u003cRagConfigLlmModel\u003e\n     */\n    public LambdaQueryWrapper\u003cRagConfigLlmModel\u003e buildQueryWrapper(String tenantId,LargeModelType largeModelType) {\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d Wrappers.lambdaQuery(RagConfigLlmModel.class);\n        lambdaQueryWrapper.eq(RagConfigLlmModel::getOnlineStatus, ToggleStatusEnum.YES.getValue());\n        // 组装当前的租户id\n        lambdaQueryWrapper.and(l -\u003e l.eq(RagConfigLlmModel::getTenantId, Cns.DEFAULT_TENANT_ID).or(f -\u003e f.eq(RagConfigLlmModel::getTenantId, tenantId)));\n        if (largeModelType!\u003dnull){\n            // 这里只查询大语言模型\n            lambdaQueryWrapper.eq(RagConfigLlmModel::getModelPurpose, largeModelType.name());\n        }\n        return lambdaQueryWrapper;\n    }\n\n    @Override\n    public List\u003cSelectGroupResp\u003e listModelGroup(String tenantId, LargeModelType largeModelType) {\n        // 查询所有在线的模型\n        List\u003cRagConfigLlmModel\u003e models \u003d this.listModelsByTypes(tenantId, largeModelType);\n        return SelectGroupResp.of(models);\n    }\n\n    @Override\n    public List\u003cRagConfigLlmModel\u003e listModelsByTypes(String tenantId, LargeModelType largeModelType) {\n        log.info(\"查询多模态大模型分组情况,tenantId:{}\",tenantId);\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d  buildQueryWrapper(tenantId,largeModelType);\n        // 查询所有在线的模型\n        return ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n    }\n\n    @Override\n    public List\u003cSelectGroupResp\u003e listModelGroup(String tenantId, LargeModelType largeModelType, boolean multi) {\n        log.info(\"查询多模态大模型分组情况-multi,tenantId:{}\",tenantId);\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d  buildQueryWrapper(tenantId,largeModelType);\n        if (multi){\n            // 只查询多模态模型\n            lambdaQueryWrapper.eq(RagConfigLlmModel::getMultiModal, ToggleStatusEnum.YES.getValue());\n        }\n        // 查询所有在线的模型\n        List\u003cRagConfigLlmModel\u003e models \u003d ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n        return SelectGroupResp.of(models);\n    }\n\n    @Override\n    public List\u003cSelectGroupResp\u003e queryLLMGroups() {\n        log.info(\"查询大模型分组情况\");\n        // 限定租户隔离情况\n        String tenantId\u003dUserContextHolder.getTenantId();\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003d  buildQueryWrapper(tenantId,LargeModelType.LARGE_LANGUAGE_MODELS);\n        // 查询所有在线的模型\n        List\u003cRagConfigLlmModel\u003e models \u003d ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n        return SelectGroupResp.of(models);\n    }\n\n    @Override\n    public List\u003cSelectResp\u003e availableModelsForSelect() {\n        // 限定租户隔离情况\n        String tenantId\u003dUserContextHolder.getTenantId();\n        // 从DB数据库里面查询\n        LambdaQueryWrapper\u003cRagConfigLlmModel\u003e lambdaQueryWrapper \u003dbuildQueryWrapper(tenantId,null);\n        List\u003cRagConfigLlmModel\u003e ragConfigLlmModels \u003d ragConfigLlmModelMapper.selectList(lambdaQueryWrapper);\n        List\u003cSelectResp\u003e result \u003d new ArrayList\u003c\u003e();\n        if (CollectionUtil.isNotEmpty(ragConfigLlmModels)) {\n            for (RagConfigLlmModel model : ragConfigLlmModels) {\n                result.add(SelectResp.builder().name(model.getName()).code(model.getModel()).build());\n            }\n        }\n        return result;\n    }\n    /**\n     * 对象转换Function\n     */\n    @AllArgsConstructor\n    private static class RagConfigLlmModelApplyFunction implements Function\u003cRagConfigLlmModel, RagConfigLlmModelResp\u003e {\n\n        final boolean displayKey;\n\n        @Override\n        public RagConfigLlmModelResp apply(RagConfigLlmModel ragConfigLlmModel) {\n            RagConfigLlmModelResp ragConfigLlmModelResp \u003d new RagConfigLlmModelResp();\n            BeanUtils.copyProperties(ragConfigLlmModel, ragConfigLlmModelResp);\n            if (LargeModelType.EMBEDDING_MODELS.name().equalsIgnoreCase(ragConfigLlmModel.getModelPurpose())){\n                ragConfigLlmModelResp.applyEmbeddingConfig(ragConfigLlmModel.getOtherConfig());\n            }else if (LargeModelType.RERANK_MODELS.name().equalsIgnoreCase(ragConfigLlmModel.getModelPurpose())) {\n                ragConfigLlmModelResp.applyRankConfig(ragConfigLlmModel.getOtherConfig());\n            }else if (LargeModelType.OCR_MODELS.name().equalsIgnoreCase(ragConfigLlmModel.getModelPurpose())) {\n                ragConfigLlmModelResp.applyOcrConfig(ragConfigLlmModel.getOtherConfig());\n            }\n            // 考虑到管理后台或者以前配置的数据没有默认值\n            if (StrUtil.isBlank(ragConfigLlmModel.getModelPurpose())){\n                ragConfigLlmModelResp.setModelPurpose(LargeModelType.LARGE_LANGUAGE_MODELS.name());\n            }\n            // 查询列表的情况下，不显示key，不暴露key给前端body\n            if (!displayKey){\n                ragConfigLlmModelResp.setSecret(StrUtil.EMPTY);\n            }\n            return ragConfigLlmModelResp;\n        }\n    }\n\n    @Override\n    public ModelConnectivityTestResp testModelConnectivity(String modelName, String testMessage) {\n        long startTime \u003d System.currentTimeMillis();\n        \n        try {\n            Optional\u003cRagConfigLlmModel\u003e modelOptional \u003d findByModelName(modelName);\n            if (modelOptional.isEmpty()) {\n                return ModelConnectivityTestResp.failure(modelName, System.currentTimeMillis() - startTime, \"未找到模型配置: \" + modelName);\n            }\n            RagConfigLlmModel model \u003d modelOptional.get();\n            if (!\"Y\".equals(model.getOnlineStatus())) {\n                return ModelConnectivityTestResp.failure(modelName, System.currentTimeMillis() - startTime, \"模型已下线\");\n            }\n            \n            log.info(\"正在测试模型连通性, modelName: {}, testMessage: {}\", modelName, testMessage);\n            String result \u003d callModelApi(model, testMessage);\n            \n            long responseTime \u003d System.currentTimeMillis() - startTime;\n            return ModelConnectivityTestResp.success(modelName, responseTime, result);\n            \n        } catch (Exception e) {\n            long responseTime \u003d System.currentTimeMillis() - startTime;\n            log.error(\"测试模型连通性失败, modelName: {}, error: {}\", modelName, e.getMessage(), e);\n            return ModelConnectivityTestResp.failure(modelName, responseTime, \"连接失败: \" + e.getMessage());\n        }\n    }\n    \n    private String callModelApi(RagConfigLlmModel model, String testMessage) throws Exception {\n        String apiUrl \u003d model.getApiUrl();\n        String[] secrets \u003d model.getSecret().split(\",\");\n        String apiKey \u003d secrets[0].trim();\n        \n        HttpHeaders headers \u003d new HttpHeaders();\n        headers.set(\"Content-Type\", \"application/json\");\n        headers.set(\"Authorization\", \"Bearer \" + apiKey);\n        \n        Map\u003cString, Object\u003e requestBody \u003d new HashMap\u003c\u003e();\n        requestBody.put(\"model\", model.getModel());\n        requestBody.put(\"enable_thinking\", false);\n        \n        List\u003cMap\u003cString, String\u003e\u003e messages \u003d new ArrayList\u003c\u003e();\n        Map\u003cString, String\u003e message \u003d new HashMap\u003c\u003e();\n        message.put(\"role\", \"user\");\n        message.put(\"content\", testMessage);\n        messages.add(message);\n        requestBody.put(\"messages\", messages);\n        \n        Map\u003cString, Object\u003e parameters \u003d new HashMap\u003c\u003e();\n        parameters.put(\"max_tokens\", 10); // 限制最大输出token数\n        parameters.put(\"temperature\", 0.1); // 降低随机性，加快响应\n        requestBody.put(\"parameters\", parameters);\n        \n        String jsonBody \u003d objectMapper.writeValueAsString(requestBody);\n        HttpEntity\u003cString\u003e request \u003d new HttpEntity\u003c\u003e(jsonBody, headers);\n        \n        RestTemplate timeoutRestTemplate \u003d new RestTemplate();\n        SimpleClientHttpRequestFactory factory \u003d  new SimpleClientHttpRequestFactory();\n        factory.setConnectTimeout(5000); // 连接超时5秒\n        factory.setReadTimeout(20000);   // 读取超时20秒\n        timeoutRestTemplate.setRequestFactory(factory);\n        timeoutRestTemplate.getMessageConverters().add(\n            new org.springframework.http.converter.StringHttpMessageConverter(java.nio.charset.StandardCharsets.UTF_8));\n        \n        // 发送请求\n        ResponseEntity\u003cString\u003e response \u003d timeoutRestTemplate.exchange(\n            apiUrl, HttpMethod.POST, request, String.class);\n        \n        if (response.getStatusCode().is2xxSuccessful()) {\n            JsonNode responseNode \u003d objectMapper.readTree(response.getBody());\n            if (responseNode.has(\"choices\") \u0026\u0026 responseNode.get(\"choices\").isArray()\n                \u0026\u0026 responseNode.get(\"choices\").size() \u003e 0) {\n                JsonNode choice \u003d responseNode.get(\"choices\").get(0);\n                if (choice.has(\"message\") \u0026\u0026 choice.get(\"message\").has(\"content\")) {\n                    return choice.get(\"message\").get(\"content\").asText();\n                }\n            }\n            return \"连通性测试成功 - API响应正常- 返回格式异常\";\n        } else {\n            throw new RuntimeException(\"API调用失败，状态码: \" + response.getStatusCode());\n        }\n    }\n    \n    /**\n     * 从配置文件批量保存模型配置\n     * @param batchSaveReq 批量保存请求\n     * @return 保存结果\n     */\n    @Transactional(rollbackFor \u003d Exception.class)\n    @Override\n    public Result\u003cString\u003e batchSaveFromConfig(RagConfigLlmModelBatchSaveReq batchSaveReq) {\n        log.info(\"从配置文件批量保存模型配置, vendorName:{}, apiKey:{}\", \n            batchSaveReq.getVendorName(), StrUtil.isNotBlank(batchSaveReq.getApiKey()) ? \"已提供\" : \"未提供\");\n        \n        try {\n            String tenantId \u003d UserContextHolder.getTenantId();\n            \n            // 1. 根据厂商名称查找厂商信息（从 plugin_vendor 表）\n            LambdaQueryWrapper\u003cPluginVendor\u003e vendorWrapper \u003d Wrappers.lambdaQuery(PluginVendor.class);\n            vendorWrapper.eq(PluginVendor::getVendorName, batchSaveReq.getVendorName());\n            vendorWrapper.eq(PluginVendor::getTenantId, tenantId);\n            PluginVendor vendor \u003d pluginVendorMapper.selectOne(vendorWrapper);\n            \n            if (vendor \u003d\u003d null) {\n                return Result.error(\"未找到对应的厂商配置，vendorName: \" + batchSaveReq.getVendorName() + \", tenantId: \" + tenantId);\n            }\n            \n            // 2. 根据厂商名称查找对应的枚举配置（从 ModelProviders 中查找）\n            ModelProviders modelProvider \u003d ModelProviders.getByName(batchSaveReq.getVendorName());\n            if (modelProvider \u003d\u003d null || modelProvider \u003d\u003d ModelProviders.None) {\n                return Result.error(\"未找到对应的厂商配置，vendorName: \" + batchSaveReq.getVendorName());\n            }\n            \n            // 检查是否有配置文件\n            if (!modelProvider.hasConfigFile()) {\n                return Result.error(\"该厂商没有配置文件，vendorName: \" + batchSaveReq.getVendorName());\n            }\n            \n            // 3. 读取配置文件\n            String configPath \u003d \"config/\" + modelProvider",
      "aiProbability": 95,
      "aiTool": "AI Assistant",
      "detectionMethod": "REALTIME_SPEED_ANALYSIS",
      "lineCount": 560
    },
    {
      "filePath": "E:/Project/hzmj/ais-server/src/main/java/com/torchv/application/system/util/VendorConfigMapper.java",
      "timestamp": 1762226981783,
      "startOffset": 4333,
      "endOffset": 7429,
      "codeContent": "品牌名称到 ModelProviders 枚举名称的映射\n     * 配置文件中的 brand 字段（中文） -\u003e ModelProviders 枚举名称\n     */\n    private static final Map\u003cString, String\u003e BRAND_TO_PROVIDER_MAP \u003d new HashMap\u003c\u003e();\n    \n    static {\n        // 初始化品牌名称到 ModelProviders 枚举名称的映射\n        BRAND_TO_PROVIDER_MAP.put(\"千问\", ModelProviders.Q_WEN.name());\n        BRAND_TO_PROVIDER_MAP.put(\"通义千问\", ModelProviders.Q_WEN.name());\n        BRAND_TO_PROVIDER_MAP.put(\"百川\", ModelProviders.Baichuan.name());\n        BRAND_TO_PROVIDER_MAP.put(\"百川智能\", ModelProviders.Baichuan.name());\n        BRAND_TO_PROVIDER_MAP.put(\"百度\", ModelProviders.Baidu.name());\n        BRAND_TO_PROVIDER_MAP.put(\"文心一言\", ModelProviders.Baidu.name());\n        BRAND_TO_PROVIDER_MAP.put(\"DeepSeek\", ModelProviders.DeepSeek.name());\n        BRAND_TO_PROVIDER_MAP.put(\"腾讯\", ModelProviders.Tencent.name());\n        BRAND_TO_PROVIDER_MAP.put(\"混元\", ModelProviders.Tencent.name());\n        BRAND_TO_PROVIDER_MAP.put(\"腾讯混元\", ModelProviders.Tencent.name());\n        BRAND_TO_PROVIDER_MAP.put(\"智谱\", ModelProviders.ChatGLM.name());\n        BRAND_TO_PROVIDER_MAP.put(\"智谱AI\", ModelProviders.ChatGLM.name());\n        BRAND_TO_PROVIDER_MAP.put(\"ChatGLM\", ModelProviders.ChatGLM.name());\n        BRAND_TO_PROVIDER_MAP.put(\"字节跳动\", ModelProviders.ByteDance.name());\n        BRAND_TO_PROVIDER_MAP.put(\"火山引擎\", ModelProviders.ByteDance.name());\n        BRAND_TO_PROVIDER_MAP.put(\"ByteDance\", ModelProviders.ByteDance.name());\n        BRAND_TO_PROVIDER_MAP.put(\"月之暗面\", ModelProviders.MoonShot.name());\n        BRAND_TO_PROVIDER_MAP.put(\"MoonShot\", ModelProviders.MoonShot.name());\n        BRAND_TO_PROVIDER_MAP.put(\"零一万物\", ModelProviders.ZeroYi.name());\n        BRAND_TO_PROVIDER_MAP.put(\"ZeroYi\", ModelProviders.ZeroYi.name());\n        BRAND_TO_PROVIDER_MAP.put(\"MiniMax\", ModelProviders.MiniMax.name());\n        BRAND_TO_PROVIDER_MAP.put(\"开源中国\", ModelProviders.OSC.name());\n        BRAND_TO_PROVIDER_MAP.put(\"OSC\", ModelProviders.OSC.name());\n        BRAND_TO_PROVIDER_MAP.put(\"OpenAI\", ModelProviders.OpenAI.name());\n        BRAND_TO_PROVIDER_MAP.put(\"Anthropic\", ModelProviders.Anthropic.name());\n        BRAND_TO_PROVIDER_MAP.put(\"Google\", ModelProviders.Google.name());\n        BRAND_TO_PROVIDER_MAP.put(\"Cohere\", ModelProviders.Cohere.name());\n        BRAND_TO_PROVIDER_MAP.put(\"Azure\", ModelProviders.Azure.name());\n        BRAND_TO_PROVIDER_MAP.put(\"Ollama\", ModelProviders.Ollama.name());\n        BRAND_TO_PROVIDER_MAP.put(\"Nvidia\", ModelProviders.Nvidia.name());\n        BRAND_TO_PROVIDER_MAP.put(\"HuggingFace\", ModelProviders.HuggingFace.name());\n        BRAND_TO_PROVIDER_MAP.put(\"Amazon\", ModelProviders.Amazon.name());\n        // 对于 ModelProviders.None 的情况，使用原品牌名称\n    }\n    \n    /**\n     * 根据品牌名称获取 ModelProviders 枚举名称\n     * @param brandName 品牌名称（配置文件中的 brand 字段）\n     * @return ModelProviders 枚举名称，如果未找到则返回原品牌名称\n     */\n    public static String getProviderNameByBrand(String brandName) {\n        if (StrUtil.isBlank(brandName)) {\n            return ModelProviders.None.name();\n        }\n        return BRAND_TO_PROVIDER_MAP.getOrDefault(brandName, brandName);\n    }\n    \n    /**\n     * ",
      "aiProbability": 95,
      "aiTool": "AI Assistant",
      "detectionMethod": "REALTIME_SPEED_ANALYSIS",
      "lineCount": 56
    },
    {
      "filePath": "/RagConfigLlmModel.java",
      "timestamp": 1762237711642,
      "startOffset": 3243,
      "endOffset": 3263,
      "codeContent": "IntellijIdeaRulezzz ",
      "aiProbability": 90,
      "aiTool": "AI Assistant",
      "detectionMethod": "REALTIME_SPEED_ANALYSIS",
      "lineCount": 1
    }
  ],
  "toolStats": {
    "AI Assistant": {
      "usageCount": 8,
      "totalLines": 784
    }
  }
}